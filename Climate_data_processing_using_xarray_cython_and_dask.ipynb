{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Data Processing\n",
    "\n",
    "Our aim is to calculate wet bulb temperature using CMIP6 data, and then look at its change. We are going to introduce how Cython and Dask will help speed up our code, and how Dask can also help us handle data that are too large to fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import intake\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from numba import njit, vectorize\n",
    "import fsspec\n",
    "xr.set_options(display_style='html') # make the display_style of xarray more user friendly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "## 1. Read in CMIP6 data in Cloud\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\")\n",
    "query = dict(experiment_id=['historical','ssp585'],\n",
    "             source_id='KACE-1-0-G',\n",
    "             table_id='3hr',\n",
    "             variable_id=['tas','huss','ps'],\n",
    "             member_id = 'r1i1p1f1')\n",
    "col_subset = col.search(require_all_on=['source_id'], **query)\n",
    "col_subset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_dict = col_subset.to_dataset_dict(zarr_kwargs={'consolidated': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dset_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only select the first and last year of this century and compare them\n",
    "hist=dset_dict['CMIP.NIMS-KMA.KACE-1-0-G.historical.3hr.gr'].sel(time='2000')\n",
    "ssp=dset_dict['ScenarioMIP.NIMS-KMA.KACE-1-0-G.ssp585.3hr.gr'].sel(time='2100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "## 2. Wet bulb temperature calculation using pure python functions\n",
    "____________\n",
    "First, we define a set of pure python functions to calculate wet bulb temperature.\n",
    "References:\n",
    "- Bolton: *The computation of equivalent potential temperature. Monthly weather review (1980) vol. 108 (7) pp. 1046-1053*\n",
    "- Davies-Jones: *An efficient and accurate method for computing the wet-bulb temperature along pseudoadiabats. Monthly Weather Review (2008) vol. 136 (7) pp. 2764-2785*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some constants\n",
    "kd = 0.2854\n",
    "lamda = 3.504\n",
    "C = 273.15\n",
    "y0 = 3036.0\n",
    "y1 = 1.78\n",
    "y2 = 0.448\n",
    "\n",
    "# return saturation vapor pressure (Pa)\n",
    "def esat(Tk):\n",
    "    # Tk: air temperature (K)\n",
    "    return 611.2*np.exp(17.67*(Tk-C)*((Tk-29.65)**(-1)))\n",
    "\n",
    "# return saturation mixing ratio (kg/kg)\n",
    "def mixrsat(Tk, ps):\n",
    "    # Tk: air temperature (K)\n",
    "    return 0.622*esat(Tk)*((ps - esat(Tk))**(-1))\n",
    "\n",
    "#return vapor pressure (Pa)\n",
    "def vaporpres(huss, ps):\n",
    "    #huss: specific humidity (kg/kg)\n",
    "    #ps: surface pressure (Pa)\n",
    "    r=huss*((1-huss)**(-1))\n",
    "    return ps*r*((0.622+r)**(-1))\n",
    "\n",
    "# return temperature at lifting condensative level\n",
    "def lcltemp(Tk,e):\n",
    "    # Tk: air temperature (K)\n",
    "    # e: vapor pressure (Pa)\n",
    "    return 2840.0*(( 3.5*np.log(Tk) - np.log(e/100.0) - 4.805)**(-1)) + 55.0\n",
    "    \n",
    "# return potential temperature at LCL (K)\n",
    "def thetadl(Tk, ps, e,Tl,mixr):\n",
    "    return Tk*((100000*((ps-e)**(-1)))**kd)*((Tk*(Tl**(-1)))**(mixr*0.00028))\n",
    "\n",
    "# return equivalent potential temperature (K)\n",
    "def thetae(theta_dl, Tl, mixr):\n",
    "    return theta_dl*np.exp(((3.036*(Tl**(-1)))-0.00178)*mixr*(1.0 + 0.000448*mixr))\n",
    "\n",
    "# 1st guess of wet bulb temperature\n",
    "def wb1stguess(X, D, Teq, ps, pi):\n",
    "    if X > D:\n",
    "        rs_teq=mixrsat(Teq,ps)\n",
    "        dlnes_dTeq = 4302.645*((Teq-29.65)**(-2))\n",
    "        wb_temp = Teq - ((2675.0*rs_teq)*((1.0 + 2675.0*rs_teq*dlnes_dTeq)**(-1)))\n",
    "    else:\n",
    "        k1 = pi*(-38.5*pi+137.81)-53.737\n",
    "        k2 = pi*(-4.392*pi+56.831)-0.384\n",
    "        if X>=1.0 and X<=D:\n",
    "            wb_temp = k1-k2*X+C\n",
    "        elif X>=0.4 and X<1:\n",
    "            wb_temp = k1-1.21-(k2-1.21)*X+C\n",
    "        else:\n",
    "            wb_temp = k1-2.66-(k2-1.21)*X+0.58*(X**(-1))+C\n",
    "    return wb_temp\n",
    "def f(wb, ps, rs_wb):\n",
    "    G=(y0*(wb**(-1))-y1)*(rs_wb*(1+y2*rs_wb))\n",
    "    return ((C*(wb**(-1)))**lamda)*(1.0 - esat(wb)*(ps**(-1)))*np.exp(-lamda*G)\n",
    "def dfdT(wb,ps,rs_wb):\n",
    "    des_dwb=esat(wb)*4302.645*((wb-29.65)**(-2))\n",
    "    pminuse = ps - esat(wb)\n",
    "    rsdT=0.622*ps*(pminuse**(-2))*des_dwb\n",
    "    dGdT = -y0*(rs_wb+y2*rs_wb*rs_wb)*(wb**(-2))+(y0*(wb**(-1))-y1)*(1.0+2.0*y2*rs_wb)*rsdT\n",
    "    return -lamda*(wb**(-1)+kd*((pminuse)**(-1))*des_dwb+dGdT)*f(wb,ps,rs_wb)\n",
    "def fwb(x, C0,C1):\n",
    "    rs=mixrsat(x,C0)\n",
    "    ff=f(x,C0,rs)\n",
    "    df=dfdT(x,C0,rs)\n",
    "    return (ff - C1)*(df**(-1))\n",
    "\n",
    "# return wet bulb temperature\n",
    "def wetbulb_py (Tk, huss, ps, xtol=0.001, rtol=8.881784197001252e-16, mitr=100):\n",
    "    Tk=np.atleast_3d(Tk)\n",
    "    huss=np.atleast_3d(huss)\n",
    "    ps=np.atleast_3d(ps)\n",
    "    x_max = Tk.shape[0]\n",
    "    y_max = Tk.shape[1]\n",
    "    z_max = Tk.shape[2]\n",
    "    result = np.zeros((x_max, y_max, z_max), dtype=np.float64)\n",
    "    for i in range(x_max):\n",
    "        for j in range(y_max):\n",
    "            for k in range(z_max):\n",
    "                ps_tmp=ps[i,j,k]\n",
    "                huss_tmp=huss[i,j,k]\n",
    "                Tk_tmp=Tk[i,j,k]\n",
    "                pi = (ps_tmp/100000)**(kd)\n",
    "                mixr=huss_tmp*((1-huss_tmp)**(-1))*1000\n",
    "                e=vaporpres(huss_tmp,ps_tmp)\n",
    "                D = (0.1859*ps_tmp/100000 + 0.6512)**(-1)\n",
    "                Tl = lcltemp(Tk_tmp,e)\n",
    "                theta_dl=thetadl(Tk_tmp, ps_tmp, e,Tl,mixr)\n",
    "                epott = thetae(theta_dl,Tl,mixr)\n",
    "                Teq = epott*pi\n",
    "                X = (C*(Teq**(-1)))**lamda\n",
    "                wb_temp=wb1stguess(X, D, Teq,ps_tmp,pi)\n",
    "                xa=wb_temp-10\n",
    "                xb=wb_temp+10\n",
    "                C0=ps_tmp\n",
    "                C1=X\n",
    "                result[i,j,k]=optimize.brentq(fwb, xa, xb, (C0,C1), xtol, rtol, mitr) # use scipy.optimize.brentq\n",
    "    return result.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate wet bulb temperature for only one time step, and look at how long it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_sample=tas_hist.tas.drop(['height'])[0,:,:].load()\n",
    "huss_sample=huss_hist.huss.drop(['height'])[0,:,:].load()\n",
    "ps_sample=ps_hist.ps[0,:,:].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time wb=wetbulb_py(tas_sample, huss_sample, ps_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "## 3. Speed up our pure python code\n",
    "____________\n",
    "Pure python code is slow, we are going to use Dask and Cython to speed it up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Dask\n",
    "Dask can speed up our code by enable parallel computing. It can also solve the problem of dataset being too large to fit in memory by doing calculations chunk by chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtemp = xr.tutorial.open_dataset(\"air_temperature\").air\n",
    "airtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can chunk it to get a dask array\n",
    "airtemp=airtemp.chunk({'time':500})\n",
    "# we get a dask array with the interface of xarray\n",
    "airtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can take off the interface of xarray by calling .data\n",
    "airtemp.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can always rechunk it\n",
    "airtemp=airtemp.chunk({'time':200})\n",
    "airtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the unit from Kelvin to degree Celsius \n",
    "airtemp_degC=airtemp-273.15\n",
    "airtemp_degC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untile we explicitly call load() or compute(), Dask actually didn't do any real calculation\n",
    "# We are doing the calculations below parallelly. However not much benefit from parallel computing since it's not a big problem\n",
    "%time airtemp_degC=airtemp_degC.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask has two families of task schedulers:\n",
    "* **Single machine scheduler:** Default scheduler, can only be used on a single machine. If you import Dask, set up a computation, and then call compute, then you will use the single-machine scheduler by default. ***We use single-machine scheduler above by default!***\n",
    "\n",
    "\n",
    "* **Distributed scheduler:** can run on a single machine or distributed across a cluster, **should be preferred even on a single machine** (offer more diagnostic features). To use the dask.distributed scheduler you must set up a Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from dask.distributed import Client\n",
    "client = Client(processes=False)\n",
    "#client = Client(n_workers=4)\n",
    "client\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Threads**: One process, multiple threads; good for numeric code that releases the GIL (like NumPy, Pandas, Scikit-Learn, Numba, …)\n",
    "\n",
    "- **Processes**: several processes (maybe also multiple threads in one process); good for pure Python objects like strings or JSON-like dictionary data that holds onto the GIL; expensive inter-process communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply customized function to dask arrays chunk by chunk: ```xr.apply_ufunc()```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return saturation vapor pressure\n",
    "def esat(Tk):\n",
    "    return 611.2*np.exp(17.67*(Tk-273.15)*((Tk-29.65)**(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=xr.apply_ufunc(esat,airtemp,dask=\"parallelized\",output_dtypes=[float])\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time es=es.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dask also enable computations across multiple nodes:**\n",
    "```python\n",
    "from dask_jobqueue import SLURMCluster # you may choose PBSCluster depending on the job scheduling system\n",
    "from dask.distributed import Client\n",
    "cluster = SLURMCluster( # setup for one node\n",
    "    queue=\"huberm\",\n",
    "    cores=24,\n",
    "    processes=1,\n",
    "    local_directory='/tmp',\n",
    "    project=\"huberm\",\n",
    "    memory=\"80 GB\",\n",
    "    walltime=\"00:30:00\",\n",
    "    interface='ib0' # choose the faster network\n",
    ")\n",
    "\n",
    "client=Client(cluster)\n",
    "cluster.scale(5) # ask for 5 nodes\n",
    "cluster.adapt(minimum=2, maximum=10) # dask also enable adapative deployments according to the work load\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tips on using Dask**:\n",
    "\n",
    "- Familiarize yourself with [Dask best practices](https://docs.dask.org/en/latest/array-best-practices.html).\n",
    "\n",
    "- Don’t use Dask! Or more specifically, only use a distributed cluster if you really need it, i.e. if your calculations are running out of memory or are taking an unacceptably long time to complete.\n",
    "\n",
    "- Start small; work on a small subset of your problem to debug before scaling up to a very large dataset.\n",
    "\n",
    "- If you use a distributed cluster, use adapative mode rather than a fixed size cluster; this will help share resources more effectively.\n",
    "\n",
    "- Use the Dask dashboard heavily to monitor the activity of your cluster.\n",
    "- Tips about chunk\n",
    "  - small enough so that many chunks can fit in memory at once\n",
    "  - large enough to avoid overhead (rare to see chunk size below 100MB)\n",
    "  - the way we chunk matters; if we often slice along 'time' dimension, it's better to chunk along it.\n",
    "- avoid too many tasks\n",
    "  - every task comes with overhead (200us ~ 1ms);  millions of tasks lead to overhead of 10 minutes ~ hours\n",
    "  - easy to create too many tasks: ```array_a+1``` can create many new tasks\n",
    "  - avoid too small chunks\n",
    "  - Fusing operations together and use ```xr.apply_ufunc()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Cython\n",
    "Cython speed up our python code by compiling it into machine code. If you want to know more about the detail, please refer to the separate jupyer notebook on Cython.\n",
    "\n",
    "Numba's ```@njit``` decorator did similar thing. However, it won't work in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cython\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our cython version function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -a --compile-args=-Ofast,-fopenmp --link-args=-fopenmp\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "from libc cimport math\n",
    "from cython.parallel import prange\n",
    "from scipy.optimize.cython_optimize cimport brentq\n",
    "    \n",
    "cdef double kd,lamda, C, y0, y1, y2\n",
    "kd = 0.2854\n",
    "lamda = 3.504\n",
    "C = 273.15\n",
    "y0 = 3036.0\n",
    "y1 = 1.78\n",
    "y2 = 0.448\n",
    "\n",
    "\n",
    "ctypedef struct wb_params:\n",
    "    double C0\n",
    "    double C1\n",
    "\n",
    "cdef double esat(double Tk) nogil:\n",
    "    return 611.2*math.exp(17.67*(Tk-C)*((Tk-29.65)**(-1)))\n",
    "\n",
    "cdef double mixrsat(double Tk,double ps) nogil:\n",
    "    return 0.622*esat(Tk)*((ps - esat(Tk))**(-1))\n",
    "\n",
    "cdef double vaporpres(double huss, double ps) nogil:\n",
    "    cdef double r\n",
    "    r=huss*((1-huss)**(-1))\n",
    "    return ps*r*((0.622+r)**(-1))\n",
    "\n",
    "cdef double lcltemp(double Tk,double e) nogil:\n",
    "    return 2840.0*(( 3.5*math.log(Tk) - math.log(e/100.0) - 4.805)**(-1)) + 55.0\n",
    "\n",
    "cdef double thetadl(double Tk, double ps, double e,double Tl,double mixr) nogil:\n",
    "    return Tk*((100000*((ps-e)**(-1)))**kd)*((Tk*(Tl**(-1)))**(mixr*0.00028))\n",
    "\n",
    "cdef double thetae(double theta_dl, double Tl, double mixr) nogil:\n",
    "    return theta_dl*math.exp(((3.036*(Tl**(-1)))-0.00178)*mixr*(1.0 + 0.000448*mixr))\n",
    "\n",
    "cdef double wb1stguess(double X, double D, double Teq, double ps, double pi) nogil:\n",
    "    cdef double rs_teq, dlnes_dTeq, wb_temp, k1, k2\n",
    "    if X > D:\n",
    "        rs_teq=mixrsat(Teq,ps)\n",
    "        dlnes_dTeq = 4302.645*((Teq-29.65)**(-2))\n",
    "        wb_temp = Teq - ((2675.0*rs_teq)*((1.0 + 2675.0*rs_teq*dlnes_dTeq)**(-1)))\n",
    "    else:\n",
    "        k1 = pi*(-38.5*pi+137.81)-53.737\n",
    "        k2 = pi*(-4.392*pi+56.831)-0.384\n",
    "        if X>=1.0 and X<=D:\n",
    "            wb_temp = k1-k2*X+C\n",
    "        elif X>=0.4 and X<1:\n",
    "            wb_temp = k1-1.21-(k2-1.21)*X+C\n",
    "        else:\n",
    "            wb_temp = k1-2.66-(k2-1.21)*X+0.58*(X**(-1))+C\n",
    "    return wb_temp\n",
    "\n",
    "cdef double f(double wb, double ps, double rs_wb) nogil:\n",
    "    cdef double G\n",
    "    G=(y0*(wb**(-1))-y1)*(rs_wb*(1+y2*rs_wb))\n",
    "    return ((C*(wb**(-1)))**lamda)*(1.0 - esat(wb)*(ps**(-1)))*math.exp(-lamda*G)\n",
    "\n",
    "cdef double dfdT(double wb,double ps,double rs_wb) nogil:\n",
    "    cdef double des_dwb, pminus, rsdT, dGdT\n",
    "    des_dwb=esat(wb)*4302.645*((wb-29.65)**(-2))\n",
    "    pminuse = ps - esat(wb) #pminus in Pa\n",
    "    rsdT=0.622*ps*(pminuse**(-2))*des_dwb\n",
    "    dGdT = -y0*(rs_wb+y2*rs_wb*rs_wb)*(wb**(-2))+(y0*(wb**(-1))-y1)*(1.0+2.0*y2*rs_wb)*rsdT\n",
    "    return -lamda*(wb**(-1)+kd*((pminuse)**(-1))*des_dwb+dGdT)*f(wb,ps,rs_wb)\n",
    "\n",
    "cdef double fwb(double x, void *args) nogil:\n",
    "    cdef wb_params *myargs = <wb_params *> args\n",
    "    cdef double rs,ff,df\n",
    "    rs=mixrsat(x,myargs.C0)\n",
    "    ff=f(x,myargs.C0,rs)\n",
    "    df=dfdT(x,myargs.C0,rs)\n",
    "    return (ff - myargs.C1)*(df**(-1))\n",
    "\n",
    "cdef double wb_brentq_wrapper(wb_params args, double xa, double xb, double xtol, double rtol, int mitr) nogil:\n",
    "    return brentq(fwb, xa, xb, <wb_params *> &args, xtol, rtol, mitr, NULL)\n",
    "\n",
    "@cython.wraparound(False)\n",
    "@cython.boundscheck(False)\n",
    "def wetbulb_cython (const double[:,:,:] Tk, const double[:,:,:] huss, const double[:,:,:] ps, double xtol=0.001, double rtol=0.0, int mitr=100000):\n",
    "    cdef const double[:, :, ::1] Tk_view=Tk.copy()\n",
    "    cdef const double[:, :, ::1] huss_view=huss.copy()\n",
    "    cdef const double[:, :, ::1] ps_view=ps.copy()\n",
    "    cdef Py_ssize_t i, j, k, x_max, y_max, z_max\n",
    "    x_max = Tk_view.shape[0]\n",
    "    y_max = Tk_view.shape[1]\n",
    "    z_max = Tk_view.shape[2]\n",
    "    result = np.zeros((x_max, y_max, z_max), dtype=np.float64)\n",
    "    cdef double[:, :, ::1] result_view = result\n",
    "    cdef double xa,xb,ps_tmp,huss_tmp,Tk_tmp,pi, mixr,e, D,Tl,theta_dl,epott,Teq,X,wb_temp\n",
    "    cdef wb_params args\n",
    "    for i in prange(x_max,nogil=True):\n",
    "        for j in range(y_max):\n",
    "            for k in range(z_max):\n",
    "                ps_tmp=ps_view[i,j,k]\n",
    "                huss_tmp=huss_view[i,j,k]\n",
    "                Tk_tmp=Tk_view[i,j,k]\n",
    "                pi = (ps_tmp/100000)**(kd)\n",
    "                mixr=huss_tmp*((1-huss_tmp)**(-1))*1000 #mixing ratio (g/kg)\n",
    "                e=vaporpres(huss_tmp,ps_tmp)\n",
    "                D = (0.1859*ps_tmp/100000 + 0.6512)**(-1)\n",
    "                Tl = lcltemp(Tk_tmp,e)\n",
    "                theta_dl=thetadl(Tk_tmp, ps_tmp, e,Tl,mixr)\n",
    "                epott = thetae(theta_dl,Tl,mixr)\n",
    "                Teq = epott*pi\n",
    "                X = (C*(Teq**(-1)))**lamda\n",
    "                wb_temp=wb1stguess(X, D, Teq,ps_tmp,pi)\n",
    "                xa=wb_temp-10\n",
    "                xb=wb_temp+10\n",
    "                args.C0=ps_tmp\n",
    "                args.C1=X\n",
    "                result_view[i,j,k]=wb_brentq_wrapper(args, xa, xb, xtol, rtol, mitr)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# our cython function require 3D output of double type. But we can be more flexible by for example fused type in Cython\n",
    "# Introduction to fused type: https://cython.readthedocs.io/en/latest/src/userguide/fusedtypes.html\n",
    "tas3d=np.atleast_3d(tas_sample).astype('float64')\n",
    "huss3d=np.atleast_3d(huss_sample).astype('float64')\n",
    "ps3d=np.atleast_3d(ps_sample).astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate again using cython version function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit wb=wetbulb_cython (tas3d, huss3d, ps3d).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "## 4. Combine both Cython and Dask to compute wet bulb temperature\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access each variable for year 2000\n",
    "tas_hist=tas_hist.tas.drop(['height']).astype('float64').chunk({'time':200})\n",
    "huss_hist=huss_hist.huss.drop(['height']).astype('float64').chunk({'time':200})\n",
    "ps_hist=ps_hist.ps.astype('float64').chunk({'time':200})\n",
    "# access each variable for year 2100\n",
    "tas_ssp=tas_ssp.tas.drop(['height']).astype('float64').chunk({'time':200})\n",
    "huss_ssp=huss_ssp.huss.drop(['height']).astype('float64').chunk({'time':200})\n",
    "ps_ssp=ps_ssp.ps.astype('float64').chunk({'time':200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_hist=xr.apply_ufunc(wetbulb_cython, tas_hist, huss_hist, ps_hist,dask=\"parallelized\",output_dtypes=[float])\n",
    "wb_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can directly write the result into disk chunk by chunk\n",
    "%time wb_hist=wb_hist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_ssp=xr.apply_ufunc(wetbulb_cython, tas_ssp, huss_ssp, ps_ssp,dask=\"parallelized\",output_dtypes=[float])\n",
    "wb_ssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time wb_ssp=wb_ssp.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_ssp.to_netcdf('./wb_ssp.nc')\n",
    "wb_hist.to_netcdf('./wb_hist.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "## 5. calculate changes in annual mean and 95th percentile of wet bulb temperature\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate changes in annual mean wet bulb temperature\n",
    "mean_diff=wb_ssp.mean('time')-wb_hist.mean('time')\n",
    "# calculate changes in annual 95th percentile of wet bulb temperature\n",
    "q95_diff=(wb_ssp.chunk({'time':-1}).quantile([0.95], 'time')-wb_hist.chunk({'time':-1}).quantile([0.95], 'time')).squeeze().drop(['quantile'])\n",
    "# rename the xarray DataArray, otherwise it would have the same name and cannot be merged\n",
    "mean_diff.name='mean_diff'\n",
    "q95_diff.name='q95_diff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=xr.merge([mean_diff,q95_diff])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_netcdf('./output.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qin",
   "language": "python",
   "name": "qin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
