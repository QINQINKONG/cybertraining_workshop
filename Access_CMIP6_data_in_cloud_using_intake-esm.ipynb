{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Data Access\n",
    "\n",
    "We will first breifly introduce the functionality of Xarray, and then access CMIP6 data in goole cloud with intake-esm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "## 1. Xarray\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import zarr\n",
    "xr.set_options(display_style='html') # make the display_style of xarray more user friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the North American air temperature dataset in Xarray tutorial\n",
    "tas = xr.tutorial.open_dataset(\"air_temperature\")\n",
    "# we have a xarray dataset: A labelled N-D array!\n",
    "tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the xarray DataArray within the Dataset; xarray hasn't load the data into memory (xarray is lazy).\n",
    "tas.air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's acess year 2013 and 2014 separately and write them to our home directory\n",
    "tas.sel(time='2013').to_netcdf('./tas_2013.nc')\n",
    "tas.sel(time='2014').to_netcdf('./tas_2014.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in one of the two files that we just output\n",
    "tas=xr.open_dataset('./tas_2013.nc')\n",
    "tas.air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tc=tas.air-273.15\n",
    "# now we do calculations, xarray loads data into memory\n",
    "# but we lost the attributes\n",
    "# that's because xarray, by default only keep attributes in unambiguous circumstances\n",
    "Tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set option globally to inform xarray always keep attributes\n",
    "# you can also pass in keep_attrs=* within many individual xarray operations \n",
    "xr.set_options(keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the calculation again: attributes are kept\n",
    "Tc=tas.air-273.15\n",
    "Tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but with wrong unit (kelvin) which we need to change manually\n",
    "Tc.attrs[\"units\"] ='degC'\n",
    "Tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's output Tc to zarr format using xarray\n",
    "# we need to change Tc from xarray DataArray to xarray Dataset first!\n",
    "Tc.to_dataset().to_zarr('./Tc_zarr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in again\n",
    "Tc_zr=xr.open_zarr('./Tc_zarr/')\n",
    "# zarr automatically chunked the array for us when we output it above. We can also manually set the chunk size\n",
    "Tc_zr.air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Above, all the chunks are stored within a directory containing many small files\n",
    "# which may not be preferable on a HPC cluster\n",
    "# zarr offer several other storage alternatives\n",
    "import bsddb3\n",
    "store = zarr.DBMStore('./Tc_zarr.bdb', open=bsddb3.btopen)\n",
    "Tc_zr.to_zarr(store)\n",
    "# we need to close the store explicitly\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xarray can open multiple files in parallel\n",
    "# by default it will be chunked in the way that each file correspond to one chunk\n",
    "tas_mf=xr.open_mfdataset('./tas_*.nc',parallel=True)\n",
    "tas_mf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lots of useful functionality of xarray: **the power of labelling!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy index by label\n",
    "tas.air.sel(time='2013-07-01',lat=slice(50,20),lon=slice(250,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual mean\n",
    "tas.air.mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zonal averages at certain latitudes\n",
    "tas.air.mean('time').sel(lat=slice(50,30)).mean('lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly mean value (climatological monthly mean if we have say 30 years)\n",
    "# groupby can be very handy\n",
    "tas.air.groupby('time.month').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample: daily maximum\n",
    "tas.air.resample({'time':'D'}).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "## 2. Acess CMIP6 data in the Cloud\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Opening a single Zarr data store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standalone Zarr data store can be opened using xarrayâ€™s ```open_zarr()``` function. The function takes a Python-native ```MutableMapping``` as input, which can be acquired from a Zarr store URL using ```fsspec```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fsspec: Filesystem interfaces to work with remote filesystems\n",
    "import fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a MutableMapping from a store URL\n",
    "mapper = fsspec.get_mapper(\"gs://cmip6/CMIP6/CMIP/AS-RCEC/TaiESM1/1pctCO2/r1i1p1f1/Amon/hfls/gn/v20200225/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in\n",
    "# consolidate metadata objects into a single one which can increase the speed of reading the array metadata\n",
    "ds = xr.open_zarr(mapper, consolidated=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Manually searching the catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait! Where can I get the zstore URL?\n",
    "\n",
    "- We can download a master CSV file enumerating all available data stores\n",
    "- we can interact with the spreadsheet through a pandas DataFrame to search and explore for relevant data using the CMIP6 controlled vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# for Google Cloud:\n",
    "df = pd.read_csv(\"https://cmip6.storage.googleapis.com/pangeo-cmip6.csv\")\n",
    "# for AWS S3:\n",
    "# df = pd.read_csv(\"https://cmip6-pds.s3.amazonaws.com/pangeo-cmip6.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query it based on your needs!\n",
    "df_subset = df.query(\"activity_id=='CMIP' & source_id=='CESM2' & table_id=='Amon' & variable_id=='tas' \\\n",
    "                     & member_id=='r1i1p1f1' & grid_label=='gn'\")\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a bunch of zstore URLs\n",
    "df_subset.zstore.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's say we want to access the last one!\n",
    "zstore = df_subset.zstore.values[-1]\n",
    "mapper = fsspec.get_mapper(zstore)\n",
    "ds = xr.open_zarr(mapper, consolidated=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 working with multiple data stores at the same time\n",
    "- It seems not user friendly to open all zstores one by one manually.\n",
    "\n",
    "- ```intake-ESM``` can help combine several data stores to form a dataset.\n",
    "\n",
    "- ```intake-ESM``` is an addon of ```intake``` which is a python package aiming to provide a consistent data access API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Google Cloud:\n",
    "\n",
    "# provide a link to an esm collection file which have a bunch of metadata including \n",
    "# how data stores can be combined to yield highly aggregated datasets\n",
    "col = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\")\n",
    "# Using this esm collection file, intake-esm connect a database (CSV file) that contains data assets locations \n",
    "# and associated metadata.\n",
    "col\n",
    "\n",
    "# for AWS S3:\n",
    "#col = intake.open_esm_datastore(\"https://cmip6-pds.s3.amazonaws.com/pangeo-cmip6.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.df.head() #viewed as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do query!\n",
    "query = dict(experiment_id=['historical'],\n",
    "             table_id='Amon',\n",
    "             variable_id=['tas','tasmax'],\n",
    "             member_id = 'r1i1p1f1',\n",
    "             grid_label='gn')\n",
    "# intake-esm provides functionality to execute queries against the catalog\n",
    "col_subset = col.search(require_all_on=['source_id'], **query)\n",
    "# subset catalog and get some metrics grouped by 'source_id'\n",
    "col_subset.df.groupby('source_id')[['experiment_id', 'variable_id', 'table_id']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset.df #viewed as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intake-esm provides functionality to directly loads data to a dictionary of xarray dataset\n",
    "dset_dict = col_subset.to_dataset_dict(zarr_kwargs={'consolidated': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dset_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we got a xarry dataset that contains two xarray DataArray\n",
    "dset_dict['CMIP.CSIRO.ACCESS-ESM1-5.historical.Amon.gn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qin",
   "language": "python",
   "name": "qin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
